# Local Coding Assistants

local.md

Local Alternatives for the Privacy-Conscious

For developers who require offline capabilities or wish to maintain the "local-only" privacy model of IntelliCode, several third-party alternatives have matured in 2025:

Continue: An open-source extension for VS Code that allows you to swap cloud models for local ones like Qwen2.5-Coder or Llama 3.1.
Tabby: A self-hosted AI coding assistant that specializes in deterministic tab-autocomplete.
BroPilot: A specialized extension for Visual Studio that connects the IDE to local LLM backends.
VS Code AI Toolkit: Microsoft's own extension for downloading and running ONNX-optimized models locally.


```
Comparison: IntelliCode vs. GitHub Copilot (2025)

Feature	            IntelliCode (Deprecated)	                GitHub Copilot Agents (New)
Primary Engine	    Local GPT-C Models	                        Cloud-based LLMs (GPT-4o, Claude, Gemini)
Data Privacy	    Local execution; code stays on machine	    Cloud-based; depends on subscription plan
Connectivity	    Works offline & in air-gapped environments	Requires active internet connection
Cost	            Free (Included in IDE)	                    Free (Metered) or Paid ($10-$39/mo)
Completion UI	Starred (‚≠ê) list items & single-line text	    Multi-line ghost text & "Agent Mode" edits
```