Offline AI

*   Offline AI Magic: Run LLMs Locally with LM Studio & .NET 9 | Jernej Kavka (JK) | SSW User Group

    *   https://www.youtube.com/watch?v=is4fO4NnjY0

*   pros

    *   data sovereignity

    *   latency - low

    *   reliability - high

*   ollama

*   docker

*    LM Studio