# LM Studio

lm-studio.md

*   good option to start with is LM Studio, as it's simple to download and run models.

let your VRAM guide you. Ideally, the entire model should fit into your VRAM to ensure good generation speed. LM Studio allows you to load the full model into VRAM or just part of it, placing the rest in RAM—but this significantly slows down text generation.

Quantization is a technique that reduces the original size of models at the cost of a bit of precision. Q4_K_M is the highest level of quantization I’d recommend.



